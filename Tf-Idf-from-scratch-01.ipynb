{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TF-IDF\n",
    "Natural Language Processing (NLP) is a sub-field of artificial intelligence that deals understanding and processing human language. In light of new advancements in machine learning, many organizations have begun applying natural language processing for translation, chatbots and candidate filtering."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "#documentA = 'the man went out for a walk'\n",
    "#documentB = 'the children sat around the fire'\n",
    "\n",
    "documentA =\"Data science is an interdisciplinary field focused on extracting knowledge from data sets, which are typically large (see big data), and applying the knowledge and actionable insights from data to solve problems in a wide range of application domains.[6] The field encompasses preparing data for analysis, formulating data science problems, analyzing data, developing data-driven solutions, and presenting findings to inform high-level decisions in a broad range of application domains\"\n",
    "documentB =\"Machine learning involves computers discovering how they can perform tasks without being explicitly programmed to do so. It involves computers learning from data provided so that they carry out certain tasks. For simple tasks assigned to computers, it is possible to program algorithms telling the machine how to execute all steps required to solve the problem at hand; on the computer's part, no learning is needed. For more advanced tasks, it can be challenging for a human to manually create the needed algorithms\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Machine learning algorithms cannot work with raw text directly. Rather, the text must be converted into vectors of numbers. In natural language processing, a common technique for extracting features from text is to place all of the words that occur in the text in a bucket. This aproach is called a bag of words model or BoW for short. It’s referred to as a “bag” of words because any information about the structure of the sentence is lost."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "bagOfWordsA = documentA.split(' ')\n",
    "bagOfWordsB = documentB.split(' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "uniqueWords = set(bagOfWordsA).union(set(bagOfWordsB))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'possible': 0, 'sets,': 1, 'developing': 1, 'how': 0, 'can': 0, 'domains': 1, 'without': 0, 'certain': 0, 'big': 1, 'needed': 0, 'of': 2, 'application': 2, 'required': 0, 'out': 0, 'machine': 0, 'decisions': 1, 'an': 1, 'domains.[6]': 1, 'programmed': 0, 'hand;': 0, 'discovering': 0, 'more': 0, 'program': 0, 'wide': 1, 'knowledge': 2, 'findings': 1, 'computers': 0, 'assigned': 0, 'inform': 1, 'learning': 0, 'solve': 1, 'part,': 0, 'focused': 1, 'tasks,': 0, 'to': 2, 'they': 0, 'being': 0, 'needed.': 0, 'interdisciplinary': 1, 'and': 3, 'do': 0, 'human': 0, 'insights': 1, 'applying': 1, 'field': 2, 'provided': 0, 'large': 1, 'challenging': 0, 'computers,': 0, 'solutions,': 1, 'so.': 0, 'the': 1, 'advanced': 0, 'are': 1, 'at': 0, 'on': 1, 'typically': 1, 'telling': 0, 'steps': 0, 'problem': 0, 'The': 1, '(see': 1, 'science': 2, 'broad': 1, 'be': 0, \"computer's\": 0, 'it': 0, 'simple': 0, 'Data': 1, 'tasks': 0, 'tasks.': 0, 'data,': 1, 'which': 1, 'problems,': 1, 'Machine': 0, 'data),': 1, 'formulating': 1, 'algorithms': 0, 'presenting': 1, 'data-driven': 1, 'create': 0, 'for': 1, 'no': 0, 'is': 1, 'a': 2, 'that': 0, 'explicitly': 0, 'so': 0, 'manually': 0, 'data': 4, 'analyzing': 1, 'in': 2, 'preparing': 1, 'execute': 0, 'range': 2, 'perform': 0, 'encompasses': 1, 'all': 0, 'extracting': 1, 'It': 0, 'problems': 1, 'involves': 0, 'For': 0, 'carry': 0, 'actionable': 1, 'analysis,': 1, 'from': 2, 'high-level': 1}\n",
      "\n",
      "**************************************************\n",
      "\n",
      "{'possible': 1, 'sets,': 0, 'developing': 0, 'how': 2, 'can': 2, 'domains': 0, 'without': 1, 'certain': 1, 'big': 0, 'needed': 1, 'of': 0, 'application': 0, 'required': 1, 'out': 1, 'machine': 1, 'decisions': 0, 'an': 0, 'domains.[6]': 0, 'programmed': 1, 'hand;': 1, 'discovering': 1, 'more': 1, 'program': 1, 'wide': 0, 'knowledge': 0, 'findings': 0, 'computers': 2, 'assigned': 1, 'inform': 0, 'learning': 3, 'solve': 1, 'part,': 1, 'focused': 0, 'tasks,': 1, 'to': 6, 'they': 2, 'being': 1, 'needed.': 1, 'interdisciplinary': 0, 'and': 0, 'do': 1, 'human': 1, 'insights': 0, 'applying': 0, 'field': 0, 'provided': 1, 'large': 0, 'challenging': 1, 'computers,': 1, 'solutions,': 0, 'so.': 1, 'the': 4, 'advanced': 1, 'are': 0, 'at': 1, 'on': 1, 'typically': 0, 'telling': 1, 'steps': 1, 'problem': 1, 'The': 0, '(see': 0, 'science': 0, 'broad': 0, 'be': 1, \"computer's\": 1, 'it': 2, 'simple': 1, 'Data': 0, 'tasks': 2, 'tasks.': 1, 'data,': 0, 'which': 0, 'problems,': 0, 'Machine': 1, 'data),': 0, 'formulating': 0, 'algorithms': 2, 'presenting': 0, 'data-driven': 0, 'create': 1, 'for': 1, 'no': 1, 'is': 2, 'a': 1, 'that': 1, 'explicitly': 1, 'so': 1, 'manually': 1, 'data': 1, 'analyzing': 0, 'in': 0, 'preparing': 0, 'execute': 1, 'range': 0, 'perform': 1, 'encompasses': 0, 'all': 1, 'extracting': 0, 'It': 1, 'problems': 0, 'involves': 2, 'For': 2, 'carry': 1, 'actionable': 0, 'analysis,': 0, 'from': 1, 'high-level': 0}\n"
     ]
    }
   ],
   "source": [
    "numOfWordsA = dict.fromkeys(uniqueWords, 0)\n",
    "for word in bagOfWordsA:\n",
    "    numOfWordsA[word] += 1\n",
    "numOfWordsB = dict.fromkeys(uniqueWords, 0)\n",
    "for word in bagOfWordsB:\n",
    "    numOfWordsB[word] += 1\n",
    "\n",
    "print(numOfWordsA)\n",
    "print()\n",
    "print(\"*\"*50)\n",
    "print()\n",
    "print(numOfWordsB)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another problem with the bag of words approach is that it doesn’t account for noise. In other words, certain words are used to formulate sentences but do not add any semantic meaning to the text. For example, the most commonly used word in the english language is 'THE' which represents 7% of all words written or spoken. You couldn’t make deduce anything about a text given the fact that it contains the word the. On the other hand, words like good and awesome could be used to determine whether a rating was positive or not.\n",
    "\n",
    "In natural language processing, useless words are referred to as stop words. The python natural language toolkit library provides a list of english stop words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['i',\n",
       " 'me',\n",
       " 'my',\n",
       " 'myself',\n",
       " 'we',\n",
       " 'our',\n",
       " 'ours',\n",
       " 'ourselves',\n",
       " 'you',\n",
       " \"you're\",\n",
       " \"you've\",\n",
       " \"you'll\",\n",
       " \"you'd\",\n",
       " 'your',\n",
       " 'yours',\n",
       " 'yourself',\n",
       " 'yourselves',\n",
       " 'he',\n",
       " 'him',\n",
       " 'his',\n",
       " 'himself',\n",
       " 'she',\n",
       " \"she's\",\n",
       " 'her',\n",
       " 'hers',\n",
       " 'herself',\n",
       " 'it',\n",
       " \"it's\",\n",
       " 'its',\n",
       " 'itself',\n",
       " 'they',\n",
       " 'them',\n",
       " 'their',\n",
       " 'theirs',\n",
       " 'themselves',\n",
       " 'what',\n",
       " 'which',\n",
       " 'who',\n",
       " 'whom',\n",
       " 'this',\n",
       " 'that',\n",
       " \"that'll\",\n",
       " 'these',\n",
       " 'those',\n",
       " 'am',\n",
       " 'is',\n",
       " 'are',\n",
       " 'was',\n",
       " 'were',\n",
       " 'be',\n",
       " 'been',\n",
       " 'being',\n",
       " 'have',\n",
       " 'has',\n",
       " 'had',\n",
       " 'having',\n",
       " 'do',\n",
       " 'does',\n",
       " 'did',\n",
       " 'doing',\n",
       " 'a',\n",
       " 'an',\n",
       " 'the',\n",
       " 'and',\n",
       " 'but',\n",
       " 'if',\n",
       " 'or',\n",
       " 'because',\n",
       " 'as',\n",
       " 'until',\n",
       " 'while',\n",
       " 'of',\n",
       " 'at',\n",
       " 'by',\n",
       " 'for',\n",
       " 'with',\n",
       " 'about',\n",
       " 'against',\n",
       " 'between',\n",
       " 'into',\n",
       " 'through',\n",
       " 'during',\n",
       " 'before',\n",
       " 'after',\n",
       " 'above',\n",
       " 'below',\n",
       " 'to',\n",
       " 'from',\n",
       " 'up',\n",
       " 'down',\n",
       " 'in',\n",
       " 'out',\n",
       " 'on',\n",
       " 'off',\n",
       " 'over',\n",
       " 'under',\n",
       " 'again',\n",
       " 'further',\n",
       " 'then',\n",
       " 'once',\n",
       " 'here',\n",
       " 'there',\n",
       " 'when',\n",
       " 'where',\n",
       " 'why',\n",
       " 'how',\n",
       " 'all',\n",
       " 'any',\n",
       " 'both',\n",
       " 'each',\n",
       " 'few',\n",
       " 'more',\n",
       " 'most',\n",
       " 'other',\n",
       " 'some',\n",
       " 'such',\n",
       " 'no',\n",
       " 'nor',\n",
       " 'not',\n",
       " 'only',\n",
       " 'own',\n",
       " 'same',\n",
       " 'so',\n",
       " 'than',\n",
       " 'too',\n",
       " 'very',\n",
       " 's',\n",
       " 't',\n",
       " 'can',\n",
       " 'will',\n",
       " 'just',\n",
       " 'don',\n",
       " \"don't\",\n",
       " 'should',\n",
       " \"should've\",\n",
       " 'now',\n",
       " 'd',\n",
       " 'll',\n",
       " 'm',\n",
       " 'o',\n",
       " 're',\n",
       " 've',\n",
       " 'y',\n",
       " 'ain',\n",
       " 'aren',\n",
       " \"aren't\",\n",
       " 'couldn',\n",
       " \"couldn't\",\n",
       " 'didn',\n",
       " \"didn't\",\n",
       " 'doesn',\n",
       " \"doesn't\",\n",
       " 'hadn',\n",
       " \"hadn't\",\n",
       " 'hasn',\n",
       " \"hasn't\",\n",
       " 'haven',\n",
       " \"haven't\",\n",
       " 'isn',\n",
       " \"isn't\",\n",
       " 'ma',\n",
       " 'mightn',\n",
       " \"mightn't\",\n",
       " 'mustn',\n",
       " \"mustn't\",\n",
       " 'needn',\n",
       " \"needn't\",\n",
       " 'shan',\n",
       " \"shan't\",\n",
       " 'shouldn',\n",
       " \"shouldn't\",\n",
       " 'wasn',\n",
       " \"wasn't\",\n",
       " 'weren',\n",
       " \"weren't\",\n",
       " 'won',\n",
       " \"won't\",\n",
       " 'wouldn',\n",
       " \"wouldn't\"]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.corpus import stopwords\n",
    "stopwords.words('english')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Term Frequency (TF)\n",
    "The number of times a word appears in a document divded by the total number of words in the document. Every document has its own term frequency.\n",
    "<img src=\"tf.png\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def computeTF(wordDict, bagOfWords):\n",
    "    tfDict = {}\n",
    "    bagOfWordsCount = len(bagOfWords)\n",
    "    print(\"*\"*20)\n",
    "    print('length of bag is ', bagOfWordsCount)\n",
    "    print(\"*\"*20)\n",
    "    for word, count in wordDict.items():\n",
    "        print(word, count)\n",
    "        tfDict[word] = count / float(bagOfWordsCount)\n",
    "        # The count of word / total len or count in bag\n",
    "    return tfDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "********************\n",
      "length of bag is  69\n",
      "********************\n",
      "possible 0\n",
      "sets, 1\n",
      "developing 1\n",
      "how 0\n",
      "can 0\n",
      "domains 1\n",
      "without 0\n",
      "certain 0\n",
      "big 1\n",
      "needed 0\n",
      "of 2\n",
      "application 2\n",
      "required 0\n",
      "out 0\n",
      "machine 0\n",
      "decisions 1\n",
      "an 1\n",
      "domains.[6] 1\n",
      "programmed 0\n",
      "hand; 0\n",
      "discovering 0\n",
      "more 0\n",
      "program 0\n",
      "wide 1\n",
      "knowledge 2\n",
      "findings 1\n",
      "computers 0\n",
      "assigned 0\n",
      "inform 1\n",
      "learning 0\n",
      "solve 1\n",
      "part, 0\n",
      "focused 1\n",
      "tasks, 0\n",
      "to 2\n",
      "they 0\n",
      "being 0\n",
      "needed. 0\n",
      "interdisciplinary 1\n",
      "and 3\n",
      "do 0\n",
      "human 0\n",
      "insights 1\n",
      "applying 1\n",
      "field 2\n",
      "provided 0\n",
      "large 1\n",
      "challenging 0\n",
      "computers, 0\n",
      "solutions, 1\n",
      "so. 0\n",
      "the 1\n",
      "advanced 0\n",
      "are 1\n",
      "at 0\n",
      "on 1\n",
      "typically 1\n",
      "telling 0\n",
      "steps 0\n",
      "problem 0\n",
      "The 1\n",
      "(see 1\n",
      "science 2\n",
      "broad 1\n",
      "be 0\n",
      "computer's 0\n",
      "it 0\n",
      "simple 0\n",
      "Data 1\n",
      "tasks 0\n",
      "tasks. 0\n",
      "data, 1\n",
      "which 1\n",
      "problems, 1\n",
      "Machine 0\n",
      "data), 1\n",
      "formulating 1\n",
      "algorithms 0\n",
      "presenting 1\n",
      "data-driven 1\n",
      "create 0\n",
      "for 1\n",
      "no 0\n",
      "is 1\n",
      "a 2\n",
      "that 0\n",
      "explicitly 0\n",
      "so 0\n",
      "manually 0\n",
      "data 4\n",
      "analyzing 1\n",
      "in 2\n",
      "preparing 1\n",
      "execute 0\n",
      "range 2\n",
      "perform 0\n",
      "encompasses 1\n",
      "all 0\n",
      "extracting 1\n",
      "It 0\n",
      "problems 1\n",
      "involves 0\n",
      "For 0\n",
      "carry 0\n",
      "actionable 1\n",
      "analysis, 1\n",
      "from 2\n",
      "high-level 1\n",
      "********************\n",
      "length of bag is  83\n",
      "********************\n",
      "possible 1\n",
      "sets, 0\n",
      "developing 0\n",
      "how 2\n",
      "can 2\n",
      "domains 0\n",
      "without 1\n",
      "certain 1\n",
      "big 0\n",
      "needed 1\n",
      "of 0\n",
      "application 0\n",
      "required 1\n",
      "out 1\n",
      "machine 1\n",
      "decisions 0\n",
      "an 0\n",
      "domains.[6] 0\n",
      "programmed 1\n",
      "hand; 1\n",
      "discovering 1\n",
      "more 1\n",
      "program 1\n",
      "wide 0\n",
      "knowledge 0\n",
      "findings 0\n",
      "computers 2\n",
      "assigned 1\n",
      "inform 0\n",
      "learning 3\n",
      "solve 1\n",
      "part, 1\n",
      "focused 0\n",
      "tasks, 1\n",
      "to 6\n",
      "they 2\n",
      "being 1\n",
      "needed. 1\n",
      "interdisciplinary 0\n",
      "and 0\n",
      "do 1\n",
      "human 1\n",
      "insights 0\n",
      "applying 0\n",
      "field 0\n",
      "provided 1\n",
      "large 0\n",
      "challenging 1\n",
      "computers, 1\n",
      "solutions, 0\n",
      "so. 1\n",
      "the 4\n",
      "advanced 1\n",
      "are 0\n",
      "at 1\n",
      "on 1\n",
      "typically 0\n",
      "telling 1\n",
      "steps 1\n",
      "problem 1\n",
      "The 0\n",
      "(see 0\n",
      "science 0\n",
      "broad 0\n",
      "be 1\n",
      "computer's 1\n",
      "it 2\n",
      "simple 1\n",
      "Data 0\n",
      "tasks 2\n",
      "tasks. 1\n",
      "data, 0\n",
      "which 0\n",
      "problems, 0\n",
      "Machine 1\n",
      "data), 0\n",
      "formulating 0\n",
      "algorithms 2\n",
      "presenting 0\n",
      "data-driven 0\n",
      "create 1\n",
      "for 1\n",
      "no 1\n",
      "is 2\n",
      "a 1\n",
      "that 1\n",
      "explicitly 1\n",
      "so 1\n",
      "manually 1\n",
      "data 1\n",
      "analyzing 0\n",
      "in 0\n",
      "preparing 0\n",
      "execute 1\n",
      "range 0\n",
      "perform 1\n",
      "encompasses 0\n",
      "all 1\n",
      "extracting 0\n",
      "It 1\n",
      "problems 0\n",
      "involves 2\n",
      "For 2\n",
      "carry 1\n",
      "actionable 0\n",
      "analysis, 0\n",
      "from 1\n",
      "high-level 0\n",
      "{'possible': 0.0, 'sets,': 0.014492753623188406, 'developing': 0.014492753623188406, 'how': 0.0, 'can': 0.0, 'domains': 0.014492753623188406, 'without': 0.0, 'certain': 0.0, 'big': 0.014492753623188406, 'needed': 0.0, 'of': 0.028985507246376812, 'application': 0.028985507246376812, 'required': 0.0, 'out': 0.0, 'machine': 0.0, 'decisions': 0.014492753623188406, 'an': 0.014492753623188406, 'domains.[6]': 0.014492753623188406, 'programmed': 0.0, 'hand;': 0.0, 'discovering': 0.0, 'more': 0.0, 'program': 0.0, 'wide': 0.014492753623188406, 'knowledge': 0.028985507246376812, 'findings': 0.014492753623188406, 'computers': 0.0, 'assigned': 0.0, 'inform': 0.014492753623188406, 'learning': 0.0, 'solve': 0.014492753623188406, 'part,': 0.0, 'focused': 0.014492753623188406, 'tasks,': 0.0, 'to': 0.028985507246376812, 'they': 0.0, 'being': 0.0, 'needed.': 0.0, 'interdisciplinary': 0.014492753623188406, 'and': 0.043478260869565216, 'do': 0.0, 'human': 0.0, 'insights': 0.014492753623188406, 'applying': 0.014492753623188406, 'field': 0.028985507246376812, 'provided': 0.0, 'large': 0.014492753623188406, 'challenging': 0.0, 'computers,': 0.0, 'solutions,': 0.014492753623188406, 'so.': 0.0, 'the': 0.014492753623188406, 'advanced': 0.0, 'are': 0.014492753623188406, 'at': 0.0, 'on': 0.014492753623188406, 'typically': 0.014492753623188406, 'telling': 0.0, 'steps': 0.0, 'problem': 0.0, 'The': 0.014492753623188406, '(see': 0.014492753623188406, 'science': 0.028985507246376812, 'broad': 0.014492753623188406, 'be': 0.0, \"computer's\": 0.0, 'it': 0.0, 'simple': 0.0, 'Data': 0.014492753623188406, 'tasks': 0.0, 'tasks.': 0.0, 'data,': 0.014492753623188406, 'which': 0.014492753623188406, 'problems,': 0.014492753623188406, 'Machine': 0.0, 'data),': 0.014492753623188406, 'formulating': 0.014492753623188406, 'algorithms': 0.0, 'presenting': 0.014492753623188406, 'data-driven': 0.014492753623188406, 'create': 0.0, 'for': 0.014492753623188406, 'no': 0.0, 'is': 0.014492753623188406, 'a': 0.028985507246376812, 'that': 0.0, 'explicitly': 0.0, 'so': 0.0, 'manually': 0.0, 'data': 0.057971014492753624, 'analyzing': 0.014492753623188406, 'in': 0.028985507246376812, 'preparing': 0.014492753623188406, 'execute': 0.0, 'range': 0.028985507246376812, 'perform': 0.0, 'encompasses': 0.014492753623188406, 'all': 0.0, 'extracting': 0.014492753623188406, 'It': 0.0, 'problems': 0.014492753623188406, 'involves': 0.0, 'For': 0.0, 'carry': 0.0, 'actionable': 0.014492753623188406, 'analysis,': 0.014492753623188406, 'from': 0.028985507246376812, 'high-level': 0.014492753623188406}\n",
      "******************************\n",
      "{'possible': 0.012048192771084338, 'sets,': 0.0, 'developing': 0.0, 'how': 0.024096385542168676, 'can': 0.024096385542168676, 'domains': 0.0, 'without': 0.012048192771084338, 'certain': 0.012048192771084338, 'big': 0.0, 'needed': 0.012048192771084338, 'of': 0.0, 'application': 0.0, 'required': 0.012048192771084338, 'out': 0.012048192771084338, 'machine': 0.012048192771084338, 'decisions': 0.0, 'an': 0.0, 'domains.[6]': 0.0, 'programmed': 0.012048192771084338, 'hand;': 0.012048192771084338, 'discovering': 0.012048192771084338, 'more': 0.012048192771084338, 'program': 0.012048192771084338, 'wide': 0.0, 'knowledge': 0.0, 'findings': 0.0, 'computers': 0.024096385542168676, 'assigned': 0.012048192771084338, 'inform': 0.0, 'learning': 0.03614457831325301, 'solve': 0.012048192771084338, 'part,': 0.012048192771084338, 'focused': 0.0, 'tasks,': 0.012048192771084338, 'to': 0.07228915662650602, 'they': 0.024096385542168676, 'being': 0.012048192771084338, 'needed.': 0.012048192771084338, 'interdisciplinary': 0.0, 'and': 0.0, 'do': 0.012048192771084338, 'human': 0.012048192771084338, 'insights': 0.0, 'applying': 0.0, 'field': 0.0, 'provided': 0.012048192771084338, 'large': 0.0, 'challenging': 0.012048192771084338, 'computers,': 0.012048192771084338, 'solutions,': 0.0, 'so.': 0.012048192771084338, 'the': 0.04819277108433735, 'advanced': 0.012048192771084338, 'are': 0.0, 'at': 0.012048192771084338, 'on': 0.012048192771084338, 'typically': 0.0, 'telling': 0.012048192771084338, 'steps': 0.012048192771084338, 'problem': 0.012048192771084338, 'The': 0.0, '(see': 0.0, 'science': 0.0, 'broad': 0.0, 'be': 0.012048192771084338, \"computer's\": 0.012048192771084338, 'it': 0.024096385542168676, 'simple': 0.012048192771084338, 'Data': 0.0, 'tasks': 0.024096385542168676, 'tasks.': 0.012048192771084338, 'data,': 0.0, 'which': 0.0, 'problems,': 0.0, 'Machine': 0.012048192771084338, 'data),': 0.0, 'formulating': 0.0, 'algorithms': 0.024096385542168676, 'presenting': 0.0, 'data-driven': 0.0, 'create': 0.012048192771084338, 'for': 0.012048192771084338, 'no': 0.012048192771084338, 'is': 0.024096385542168676, 'a': 0.012048192771084338, 'that': 0.012048192771084338, 'explicitly': 0.012048192771084338, 'so': 0.012048192771084338, 'manually': 0.012048192771084338, 'data': 0.012048192771084338, 'analyzing': 0.0, 'in': 0.0, 'preparing': 0.0, 'execute': 0.012048192771084338, 'range': 0.0, 'perform': 0.012048192771084338, 'encompasses': 0.0, 'all': 0.012048192771084338, 'extracting': 0.0, 'It': 0.012048192771084338, 'problems': 0.0, 'involves': 0.024096385542168676, 'For': 0.024096385542168676, 'carry': 0.012048192771084338, 'actionable': 0.0, 'analysis,': 0.0, 'from': 0.012048192771084338, 'high-level': 0.0}\n"
     ]
    }
   ],
   "source": [
    "tfA = computeTF(numOfWordsA, bagOfWordsA)\n",
    "tfB = computeTF(numOfWordsB, bagOfWordsB)\n",
    "print(tfA)\n",
    "print(\"*\"*30)\n",
    "print(tfB)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inverse Data Frequency (IDF)\n",
    "The log of the number of documents divided by the number of documents that contain the word w. Inverse data frequency determines the weight of rare words across all documents in the corpus.\n",
    "<img src=\"idf.png\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def computeIDF(documents):\n",
    "    import math\n",
    "    N = len(documents)\n",
    "    print(N) # here N = 2\n",
    "    print(\"*\"*30)\n",
    "    idfDict = dict.fromkeys(documents[1].keys(), 0)\n",
    "    print(idfDict)\n",
    "    print(\"*\"*30)\n",
    "    for document in documents:\n",
    "        for word, count in document.items():\n",
    "            print(word , count)\n",
    "            if count > 0:\n",
    "                idfDict[word] += 1\n",
    "        print(\"*\"*10)\n",
    "    print(idfDict)\n",
    "    print(\"*\"*30)\n",
    "    for word, count in idfDict.items():\n",
    "        idfDict[word] = math.log(N / float(count))\n",
    "    return idfDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "******************************\n",
      "{'possible': 0, 'sets,': 0, 'developing': 0, 'how': 0, 'can': 0, 'domains': 0, 'without': 0, 'certain': 0, 'big': 0, 'needed': 0, 'of': 0, 'application': 0, 'required': 0, 'out': 0, 'machine': 0, 'decisions': 0, 'an': 0, 'domains.[6]': 0, 'programmed': 0, 'hand;': 0, 'discovering': 0, 'more': 0, 'program': 0, 'wide': 0, 'knowledge': 0, 'findings': 0, 'computers': 0, 'assigned': 0, 'inform': 0, 'learning': 0, 'solve': 0, 'part,': 0, 'focused': 0, 'tasks,': 0, 'to': 0, 'they': 0, 'being': 0, 'needed.': 0, 'interdisciplinary': 0, 'and': 0, 'do': 0, 'human': 0, 'insights': 0, 'applying': 0, 'field': 0, 'provided': 0, 'large': 0, 'challenging': 0, 'computers,': 0, 'solutions,': 0, 'so.': 0, 'the': 0, 'advanced': 0, 'are': 0, 'at': 0, 'on': 0, 'typically': 0, 'telling': 0, 'steps': 0, 'problem': 0, 'The': 0, '(see': 0, 'science': 0, 'broad': 0, 'be': 0, \"computer's\": 0, 'it': 0, 'simple': 0, 'Data': 0, 'tasks': 0, 'tasks.': 0, 'data,': 0, 'which': 0, 'problems,': 0, 'Machine': 0, 'data),': 0, 'formulating': 0, 'algorithms': 0, 'presenting': 0, 'data-driven': 0, 'create': 0, 'for': 0, 'no': 0, 'is': 0, 'a': 0, 'that': 0, 'explicitly': 0, 'so': 0, 'manually': 0, 'data': 0, 'analyzing': 0, 'in': 0, 'preparing': 0, 'execute': 0, 'range': 0, 'perform': 0, 'encompasses': 0, 'all': 0, 'extracting': 0, 'It': 0, 'problems': 0, 'involves': 0, 'For': 0, 'carry': 0, 'actionable': 0, 'analysis,': 0, 'from': 0, 'high-level': 0}\n",
      "******************************\n",
      "possible 0\n",
      "sets, 1\n",
      "developing 1\n",
      "how 0\n",
      "can 0\n",
      "domains 1\n",
      "without 0\n",
      "certain 0\n",
      "big 1\n",
      "needed 0\n",
      "of 2\n",
      "application 2\n",
      "required 0\n",
      "out 0\n",
      "machine 0\n",
      "decisions 1\n",
      "an 1\n",
      "domains.[6] 1\n",
      "programmed 0\n",
      "hand; 0\n",
      "discovering 0\n",
      "more 0\n",
      "program 0\n",
      "wide 1\n",
      "knowledge 2\n",
      "findings 1\n",
      "computers 0\n",
      "assigned 0\n",
      "inform 1\n",
      "learning 0\n",
      "solve 1\n",
      "part, 0\n",
      "focused 1\n",
      "tasks, 0\n",
      "to 2\n",
      "they 0\n",
      "being 0\n",
      "needed. 0\n",
      "interdisciplinary 1\n",
      "and 3\n",
      "do 0\n",
      "human 0\n",
      "insights 1\n",
      "applying 1\n",
      "field 2\n",
      "provided 0\n",
      "large 1\n",
      "challenging 0\n",
      "computers, 0\n",
      "solutions, 1\n",
      "so. 0\n",
      "the 1\n",
      "advanced 0\n",
      "are 1\n",
      "at 0\n",
      "on 1\n",
      "typically 1\n",
      "telling 0\n",
      "steps 0\n",
      "problem 0\n",
      "The 1\n",
      "(see 1\n",
      "science 2\n",
      "broad 1\n",
      "be 0\n",
      "computer's 0\n",
      "it 0\n",
      "simple 0\n",
      "Data 1\n",
      "tasks 0\n",
      "tasks. 0\n",
      "data, 1\n",
      "which 1\n",
      "problems, 1\n",
      "Machine 0\n",
      "data), 1\n",
      "formulating 1\n",
      "algorithms 0\n",
      "presenting 1\n",
      "data-driven 1\n",
      "create 0\n",
      "for 1\n",
      "no 0\n",
      "is 1\n",
      "a 2\n",
      "that 0\n",
      "explicitly 0\n",
      "so 0\n",
      "manually 0\n",
      "data 4\n",
      "analyzing 1\n",
      "in 2\n",
      "preparing 1\n",
      "execute 0\n",
      "range 2\n",
      "perform 0\n",
      "encompasses 1\n",
      "all 0\n",
      "extracting 1\n",
      "It 0\n",
      "problems 1\n",
      "involves 0\n",
      "For 0\n",
      "carry 0\n",
      "actionable 1\n",
      "analysis, 1\n",
      "from 2\n",
      "high-level 1\n",
      "**********\n",
      "possible 1\n",
      "sets, 0\n",
      "developing 0\n",
      "how 2\n",
      "can 2\n",
      "domains 0\n",
      "without 1\n",
      "certain 1\n",
      "big 0\n",
      "needed 1\n",
      "of 0\n",
      "application 0\n",
      "required 1\n",
      "out 1\n",
      "machine 1\n",
      "decisions 0\n",
      "an 0\n",
      "domains.[6] 0\n",
      "programmed 1\n",
      "hand; 1\n",
      "discovering 1\n",
      "more 1\n",
      "program 1\n",
      "wide 0\n",
      "knowledge 0\n",
      "findings 0\n",
      "computers 2\n",
      "assigned 1\n",
      "inform 0\n",
      "learning 3\n",
      "solve 1\n",
      "part, 1\n",
      "focused 0\n",
      "tasks, 1\n",
      "to 6\n",
      "they 2\n",
      "being 1\n",
      "needed. 1\n",
      "interdisciplinary 0\n",
      "and 0\n",
      "do 1\n",
      "human 1\n",
      "insights 0\n",
      "applying 0\n",
      "field 0\n",
      "provided 1\n",
      "large 0\n",
      "challenging 1\n",
      "computers, 1\n",
      "solutions, 0\n",
      "so. 1\n",
      "the 4\n",
      "advanced 1\n",
      "are 0\n",
      "at 1\n",
      "on 1\n",
      "typically 0\n",
      "telling 1\n",
      "steps 1\n",
      "problem 1\n",
      "The 0\n",
      "(see 0\n",
      "science 0\n",
      "broad 0\n",
      "be 1\n",
      "computer's 1\n",
      "it 2\n",
      "simple 1\n",
      "Data 0\n",
      "tasks 2\n",
      "tasks. 1\n",
      "data, 0\n",
      "which 0\n",
      "problems, 0\n",
      "Machine 1\n",
      "data), 0\n",
      "formulating 0\n",
      "algorithms 2\n",
      "presenting 0\n",
      "data-driven 0\n",
      "create 1\n",
      "for 1\n",
      "no 1\n",
      "is 2\n",
      "a 1\n",
      "that 1\n",
      "explicitly 1\n",
      "so 1\n",
      "manually 1\n",
      "data 1\n",
      "analyzing 0\n",
      "in 0\n",
      "preparing 0\n",
      "execute 1\n",
      "range 0\n",
      "perform 1\n",
      "encompasses 0\n",
      "all 1\n",
      "extracting 0\n",
      "It 1\n",
      "problems 0\n",
      "involves 2\n",
      "For 2\n",
      "carry 1\n",
      "actionable 0\n",
      "analysis, 0\n",
      "from 1\n",
      "high-level 0\n",
      "**********\n",
      "{'possible': 1, 'sets,': 1, 'developing': 1, 'how': 1, 'can': 1, 'domains': 1, 'without': 1, 'certain': 1, 'big': 1, 'needed': 1, 'of': 1, 'application': 1, 'required': 1, 'out': 1, 'machine': 1, 'decisions': 1, 'an': 1, 'domains.[6]': 1, 'programmed': 1, 'hand;': 1, 'discovering': 1, 'more': 1, 'program': 1, 'wide': 1, 'knowledge': 1, 'findings': 1, 'computers': 1, 'assigned': 1, 'inform': 1, 'learning': 1, 'solve': 2, 'part,': 1, 'focused': 1, 'tasks,': 1, 'to': 2, 'they': 1, 'being': 1, 'needed.': 1, 'interdisciplinary': 1, 'and': 1, 'do': 1, 'human': 1, 'insights': 1, 'applying': 1, 'field': 1, 'provided': 1, 'large': 1, 'challenging': 1, 'computers,': 1, 'solutions,': 1, 'so.': 1, 'the': 2, 'advanced': 1, 'are': 1, 'at': 1, 'on': 2, 'typically': 1, 'telling': 1, 'steps': 1, 'problem': 1, 'The': 1, '(see': 1, 'science': 1, 'broad': 1, 'be': 1, \"computer's\": 1, 'it': 1, 'simple': 1, 'Data': 1, 'tasks': 1, 'tasks.': 1, 'data,': 1, 'which': 1, 'problems,': 1, 'Machine': 1, 'data),': 1, 'formulating': 1, 'algorithms': 1, 'presenting': 1, 'data-driven': 1, 'create': 1, 'for': 2, 'no': 1, 'is': 2, 'a': 2, 'that': 1, 'explicitly': 1, 'so': 1, 'manually': 1, 'data': 2, 'analyzing': 1, 'in': 1, 'preparing': 1, 'execute': 1, 'range': 1, 'perform': 1, 'encompasses': 1, 'all': 1, 'extracting': 1, 'It': 1, 'problems': 1, 'involves': 1, 'For': 1, 'carry': 1, 'actionable': 1, 'analysis,': 1, 'from': 2, 'high-level': 1}\n",
      "******************************\n",
      "{'possible': 0.6931471805599453, 'sets,': 0.6931471805599453, 'developing': 0.6931471805599453, 'how': 0.6931471805599453, 'can': 0.6931471805599453, 'domains': 0.6931471805599453, 'without': 0.6931471805599453, 'certain': 0.6931471805599453, 'big': 0.6931471805599453, 'needed': 0.6931471805599453, 'of': 0.6931471805599453, 'application': 0.6931471805599453, 'required': 0.6931471805599453, 'out': 0.6931471805599453, 'machine': 0.6931471805599453, 'decisions': 0.6931471805599453, 'an': 0.6931471805599453, 'domains.[6]': 0.6931471805599453, 'programmed': 0.6931471805599453, 'hand;': 0.6931471805599453, 'discovering': 0.6931471805599453, 'more': 0.6931471805599453, 'program': 0.6931471805599453, 'wide': 0.6931471805599453, 'knowledge': 0.6931471805599453, 'findings': 0.6931471805599453, 'computers': 0.6931471805599453, 'assigned': 0.6931471805599453, 'inform': 0.6931471805599453, 'learning': 0.6931471805599453, 'solve': 0.0, 'part,': 0.6931471805599453, 'focused': 0.6931471805599453, 'tasks,': 0.6931471805599453, 'to': 0.0, 'they': 0.6931471805599453, 'being': 0.6931471805599453, 'needed.': 0.6931471805599453, 'interdisciplinary': 0.6931471805599453, 'and': 0.6931471805599453, 'do': 0.6931471805599453, 'human': 0.6931471805599453, 'insights': 0.6931471805599453, 'applying': 0.6931471805599453, 'field': 0.6931471805599453, 'provided': 0.6931471805599453, 'large': 0.6931471805599453, 'challenging': 0.6931471805599453, 'computers,': 0.6931471805599453, 'solutions,': 0.6931471805599453, 'so.': 0.6931471805599453, 'the': 0.0, 'advanced': 0.6931471805599453, 'are': 0.6931471805599453, 'at': 0.6931471805599453, 'on': 0.0, 'typically': 0.6931471805599453, 'telling': 0.6931471805599453, 'steps': 0.6931471805599453, 'problem': 0.6931471805599453, 'The': 0.6931471805599453, '(see': 0.6931471805599453, 'science': 0.6931471805599453, 'broad': 0.6931471805599453, 'be': 0.6931471805599453, \"computer's\": 0.6931471805599453, 'it': 0.6931471805599453, 'simple': 0.6931471805599453, 'Data': 0.6931471805599453, 'tasks': 0.6931471805599453, 'tasks.': 0.6931471805599453, 'data,': 0.6931471805599453, 'which': 0.6931471805599453, 'problems,': 0.6931471805599453, 'Machine': 0.6931471805599453, 'data),': 0.6931471805599453, 'formulating': 0.6931471805599453, 'algorithms': 0.6931471805599453, 'presenting': 0.6931471805599453, 'data-driven': 0.6931471805599453, 'create': 0.6931471805599453, 'for': 0.0, 'no': 0.6931471805599453, 'is': 0.0, 'a': 0.0, 'that': 0.6931471805599453, 'explicitly': 0.6931471805599453, 'so': 0.6931471805599453, 'manually': 0.6931471805599453, 'data': 0.0, 'analyzing': 0.6931471805599453, 'in': 0.6931471805599453, 'preparing': 0.6931471805599453, 'execute': 0.6931471805599453, 'range': 0.6931471805599453, 'perform': 0.6931471805599453, 'encompasses': 0.6931471805599453, 'all': 0.6931471805599453, 'extracting': 0.6931471805599453, 'It': 0.6931471805599453, 'problems': 0.6931471805599453, 'involves': 0.6931471805599453, 'For': 0.6931471805599453, 'carry': 0.6931471805599453, 'actionable': 0.6931471805599453, 'analysis,': 0.6931471805599453, 'from': 0.0, 'high-level': 0.6931471805599453}\n"
     ]
    }
   ],
   "source": [
    "idfs = computeIDF([numOfWordsA, numOfWordsB])\n",
    "print(idfs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lastly, the TF-IDF is simply the TF multiplied by IDF.\n",
    "<img src=\"tfidf.png\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def computeTFIDF(tfBagOfWords, idfs):\n",
    "    tfidf = {}\n",
    "    for word, val in tfBagOfWords.items():\n",
    "        tfidf[word] = val * idfs[word]\n",
    "    return tfidf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   possible     sets,  developing       how       can   domains   without  \\\n",
      "0  0.000000  0.010046    0.010046  0.000000  0.000000  0.010046  0.000000   \n",
      "1  0.008351  0.000000    0.000000  0.016702  0.016702  0.000000  0.008351   \n",
      "\n",
      "    certain       big    needed  ...  extracting        It  problems  \\\n",
      "0  0.000000  0.010046  0.000000  ...    0.010046  0.000000  0.010046   \n",
      "1  0.008351  0.000000  0.008351  ...    0.000000  0.008351  0.000000   \n",
      "\n",
      "   involves       For     carry  actionable  analysis,  from  high-level  \n",
      "0  0.000000  0.000000  0.000000    0.010046   0.010046   0.0    0.010046  \n",
      "1  0.016702  0.016702  0.008351    0.000000   0.000000   0.0    0.000000  \n",
      "\n",
      "[2 rows x 108 columns]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"\\ndocumentA = 'the man went out for a walk'\\ndocumentB = 'the children sat around the fire'\\n\""
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidfA = computeTFIDF(tfA, idfs)\n",
    "tfidfB = computeTFIDF(tfB, idfs)\n",
    "df = pd.DataFrame([tfidfA, tfidfB])\n",
    "print(df)\n",
    "\n",
    "'''\n",
    "documentA = 'the man went out for a walk'\n",
    "documentB = 'the children sat around the fire'\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   actionable  advanced  algorithms       all        an  analysis  analyzing  \\\n",
      "0    0.093049  0.000000    0.000000  0.000000  0.093049  0.093049   0.093049   \n",
      "1    0.000000  0.083353    0.166707  0.083353  0.000000  0.000000   0.000000   \n",
      "\n",
      "        and  application  applying  ...     tasks   telling      that  \\\n",
      "0  0.279146     0.186097  0.093049  ...  0.000000  0.000000  0.000000   \n",
      "1  0.000000     0.000000  0.000000  ...  0.333413  0.083353  0.083353   \n",
      "\n",
      "        the      they       to  typically     which      wide   without  \n",
      "0  0.132410  0.000000  0.13241   0.093049  0.093049  0.093049  0.000000  \n",
      "1  0.237226  0.166707  0.35584   0.000000  0.000000  0.000000  0.083353  \n",
      "\n",
      "[2 rows x 94 columns]\n"
     ]
    }
   ],
   "source": [
    "# Using Sklearn pkg\n",
    "\n",
    "vectorizer = TfidfVectorizer()\n",
    "vectors = vectorizer.fit_transform([documentA, documentB])\n",
    "feature_names = vectorizer.get_feature_names()\n",
    "dense = vectors.todense()\n",
    "denselist = dense.tolist()\n",
    "df = pd.DataFrame(denselist, columns=feature_names)\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
